{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lfs import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, average_precision_score, roc_auc_score, cohen_kappa_score, accuracy_score\n",
    "\n",
    "hint_path = './clinical-trial-outcome-prediction/data/'\n",
    "all_files = glob.glob(os.path.join(hint_path, \"phase*train.csv\")) + glob.glob(os.path.join(hint_path, \"phase*valid.csv\"))\n",
    "hint = pd.concat((pd.read_csv(f) for f in all_files))\n",
    "hint.rename(columns={'nctid': 'nct_id'}, inplace=True)\n",
    "print(hint['label'].value_counts())\n",
    "\n",
    "path = '../CTTI/'\n",
    "# study_df = pd.read_csv('../CTTI/studies.txt', sep='|')\n",
    "# study_df.dropna(subset=['phase'], inplace=True)\n",
    "# study_df[study_df['phase'].str.contains('1')].shape[0], study_df[study_df['phase'].str.contains('2')].shape[0], study_df[study_df['phase'].str.contains('3')].shape[0]\n",
    "phase_1_sum, phase_2_sum, phase_3_sum = 60549, 76972, 44087\n",
    "\n",
    "# print('lf, phase, qunatile, -1.0, 0.0, 1.0, prop, coverage, acc, ck')\n",
    "quantile_list = [.1, .2, .3, .4, .5, .6, .7, .8, .9,]\n",
    "\n",
    "output = []\n",
    "for quantile in tqdm(quantile_list):\n",
    "    funcs_all = [lf_num_sponsors(quantile=quantile), \n",
    "                 lf_num_patients(quantile=quantile), \n",
    "                 lf_patient_drop(quantile=quantile), \n",
    "                 lf_sites(quantile=quantile), \n",
    "                 lf_pvalues(quantile=quantile), \n",
    "                 lf_update_more_recent(quantile=quantile), \n",
    "                 lf_death_ae(quantile=quantile), \n",
    "                 lf_serious_ae(quantile=quantile), \n",
    "                 lf_all_ae(quantile=quantile), \n",
    "                 lf_status(), \n",
    "                 lf_amendments(quantile=quantile), \n",
    "                 lf_news_headlines(quantile=quantile)]\n",
    "    funcs_all_name = ['num_sponsors', 'num_patients', 'patient_drop', 'sites', 'pvalues', 'update_more_recent', 'death_ae', 'serious_ae', 'all_ae', 'status', 'amendments', 'news_headlines']\n",
    "\n",
    "    for i in range(len(funcs_all)):\n",
    "        for phase in ['1', '2', '3']:\n",
    "            names = funcs_all_name[i] \n",
    "\n",
    "            labels_df = hint[hint['phase'].str.contains(phase)]\n",
    "            funcs = funcs_all[i][funcs_all[i]['nct_id'].isin(labels_df['nct_id'])]\n",
    "            value_counts = funcs['lf'].value_counts()\n",
    "            value_dict = value_counts.to_dict()\n",
    "\n",
    "            for key in [-1.0, 0.0, 1.0]:\n",
    "                if key not in value_dict:\n",
    "                    value_dict[key] = 0\n",
    "\n",
    "            positive_perc = value_dict[1.0] / (value_dict[1.0] + value_dict[0.0])\n",
    "            if phase == '1':\n",
    "                len_all_trials = phase_1_sum\n",
    "            elif phase == '2':\n",
    "                len_all_trials = phase_2_sum\n",
    "            else:\n",
    "                len_all_trials = phase_3_sum\n",
    "            coverage = sum([value_dict[k] for k in value_dict.keys() if k!=-1.0]) / len_all_trials\n",
    "\n",
    "            combined = pd.merge(labels_df.copy(), funcs, on='nct_id', how='left')\n",
    "            combined = combined[combined['lf'] != -1].dropna(subset=['lf'])\n",
    "\n",
    "            output.append(f\"{names}, {phase}, {quantile}, {value_dict[-1.0]}, {value_dict[0.0]}, {value_dict[1.0]}, {positive_perc}, {coverage}, \\\n",
    "                        {accuracy_score(combined['label'], combined['lf'])}, {cohen_kappa_score(combined['label'], combined['lf'])}\")\n",
    "            # print(output[-1])\n",
    "df = pd.DataFrame([x.split(',') for x in output], columns=['lf', 'phase', 'quantile', '-1.0', '0.0', '1.0', 'positive_perc', 'coverage', 'acc', 'ck'])\n",
    "df.to_csv('lf_each_thresh.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels based on best threshold\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from lfs import get_lfs\n",
    "\n",
    "df_list, status_lf = get_lfs(path='../CTTI/', lf_each_thresh_path='./lf_each_thresh.csv')\n",
    "\n",
    "path = './clinical-trial-outcome-prediction/data/'\n",
    "# all_files = glob.glob(os.path.join(path, \"phase*train.csv\")) + glob.glob(os.path.join(path, \"phase*valid.csv\")) + glob.glob(os.path.join(path, \"phase*test.csv\"))\n",
    "all_files = glob.glob(os.path.join(path, \"phase*test.csv\"))\n",
    "hint = pd.concat((pd.read_csv(f) for f in all_files))\n",
    "hint.rename(columns={'nctid': 'nct_id'}, inplace=True)\n",
    "print(hint['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, average_precision_score, roc_auc_score, accuracy_score, cohen_kappa_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from snorkel.labeling.model import LabelModel, MajorityLabelVoter\n",
    "import pandas as pd\n",
    "bad_top_test_df = pd.read_csv('./mismatched_status.csv').rename(columns={'nctid': 'nct_id'})\n",
    "\n",
    "positive_props = [.4, .5, .5]\n",
    "lrs = [.01, .01, .01]\n",
    "all_combineds = []\n",
    "all_combined_full = []\n",
    "all_phases = ['1', '2', '3']\n",
    "\n",
    "print(\"phase, acc, f1, prauc, rocauc, kappa\")\n",
    "for i in [0,1,2]:\n",
    "    phase = all_phases[i]\n",
    "    df2 = df_list[i].copy()\n",
    "    L = df2.iloc[:,1:].values.astype('int')\n",
    "\n",
    "    label_model = LabelModel(verbose=False, cardinality=2)\n",
    "    # label_model = MajorityLabelVoter(cardinality=2)\n",
    "\n",
    "    positive_prop = positive_props[i]\n",
    "    label_model.fit(L, class_balance=[1-positive_prop, positive_prop], seed=0, lr=lrs[i], n_epochs=200)\n",
    "    pred = label_model.predict(L)\n",
    "    df2['pred'] = pred.astype('int')\n",
    "\n",
    "    df2 = df2.sort_values('nct_id')\n",
    "    status_subset = status_lf[status_lf['lf']!=-1]\n",
    "    status_subset_dict = dict(zip(status_subset['nct_id'], status_subset['lf']))\n",
    "    df2['pred'] = df2.apply(lambda x: status_subset_dict[x['nct_id']] if x['nct_id'] in status_subset_dict else x['pred'], axis=1)\n",
    "\n",
    "    all_combined_full.append(df2.copy())\n",
    "\n",
    "    hint_subset = hint[hint['phase'].str.contains(phase)]\n",
    "    hint_subset = hint_subset[~hint_subset['nct_id'].isin(bad_top_test_df['nct_id'])]\n",
    "    combined = pd.merge(hint_subset, df2, on='nct_id', how='left')\n",
    "    combined = combined.dropna(subset=['pred'])\n",
    "    combined = combined[combined['pred'] != -1]\n",
    "    # print(phase, hint_subset.shape, combined.shape)\n",
    "    print(phase,',', accuracy_score(combined['label'], combined['pred']), ',',\n",
    "        f1_score(combined['label'], combined['pred']), ',', \n",
    "        average_precision_score(combined['label'], combined['pred']), ',',\n",
    "        roc_auc_score(combined['label'], combined['pred']), ',',\n",
    "        cohen_kappa_score(combined['label'], combined['pred']))\n",
    "\n",
    "    all_combineds.append(combined)\n",
    "\n",
    "combined = pd.concat(all_combineds)\n",
    "print('all',',', accuracy_score(combined['label'], combined['pred']), ',',\n",
    "    f1_score(combined['label'], combined['pred']), ',', \n",
    "    average_precision_score(combined['label'], combined['pred']), ',',\n",
    "    roc_auc_score(combined['label'], combined['pred']), ',',\n",
    "    cohen_kappa_score(combined['label'], combined['pred']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined['label'].value_counts() / combined['label'].value_counts().sum())\n",
    "print(combined['pred'].value_counts() / combined['pred'].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save to csv\n",
    "# # if dp or rf, save accordingly\n",
    "# all_combineds[0].to_csv('dp_weakpred_phase1.csv', index=False)\n",
    "# all_combineds[1].to_csv('dp_weakpred_phase2.csv', index=False)\n",
    "# all_combineds[2].to_csv('dp_weakpred_phase3.csv', index=False)\n",
    "\n",
    "# NOTE THAT THESE CONTAIN ALL PREDICTIONS FOR ALL PHASES, NOT JUST THE SPECIFIC PHASE, SO NEED TO FILTER\n",
    "print(pd.read_csv('dp_weakpred_phase1.csv').shape)\n",
    "print(pd.read_csv('dp_weakpred_phase2.csv').shape)\n",
    "print(pd.read_csv('dp_weakpred_phase3.csv').shape)\n",
    "\n",
    "print(pd.read_csv('rf_weakpred_phase1.csv').shape)\n",
    "print(pd.read_csv('rf_weakpred_phase2.csv').shape)\n",
    "print(pd.read_csv('rf_weakpred_phase3.csv').shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distilltab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
