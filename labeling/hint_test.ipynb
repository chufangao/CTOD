{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_d = []\n",
    "hint_path = './clinical-trial-outcome-prediction/data/'\n",
    "\n",
    "# for phase in ['I', 'II', 'III']:\n",
    "for phase in [ 'III']:\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        d = pd.read_csv(hint_path+'phase_{}_{}.csv'.format(phase, split))\n",
    "        d['split'] = split\n",
    "        d['phase'] = phase\n",
    "        \n",
    "        d['icdcodes'].fillna('', inplace=True)\n",
    "        d['criteria'].fillna('', inplace=True)\n",
    "\n",
    "        d['criteria'] = d['criteria'].str.replace('\\n','')\n",
    "        d['icdcodes'] = d['icdcodes'].str.replace('[','')\n",
    "        d['icdcodes'] = d['icdcodes'].str.replace(']','')\n",
    "        d['icdcodes'] = d['icdcodes'].str.replace('\\'','')\n",
    "        d['icdcodes'] = d['icdcodes'].str.replace(',','')\n",
    "\n",
    "        d['sentences'] = d[['icdcodes', 'criteria']].agg(' . '.join, axis=1)\n",
    "        all_d.append(d)\n",
    "\n",
    "d = pd.concat(all_d)\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.linear_model\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_eval_(labels, preds):\n",
    "    prauc = sklearn.metrics.average_precision_score(y_true=labels, y_score=preds[:,1])\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        rocauc = sklearn.metrics.roc_auc_score(y_true=labels, y_score=preds[:,1])\n",
    "    else:\n",
    "        rocauc = np.nan\n",
    "    f1 = sklearn.metrics.f1_score(y_true=labels, y_pred=preds.argmax(axis=1))\n",
    "    acc = sklearn.metrics.accuracy_score(y_true=labels, y_pred=preds.argmax(axis=1))\n",
    "    return prauc, rocauc, f1, acc\n",
    "    \n",
    "def bootstrap_eval(labels, preds, n_bootstrap=20, random_state=0):\n",
    "    prauc_list = []\n",
    "    rocauc_list = []\n",
    "    f1_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    np.random.seed(seed=random_state)\n",
    "    for i in range(n_bootstrap):\n",
    "        bootstrap_inds = np.random.randint(0, len(labels), size=len(labels))\n",
    "        prauc, rocauc, f1, acc = bootstrap_eval_(labels=labels[bootstrap_inds], preds=preds[bootstrap_inds])\n",
    "        prauc_list.append(prauc)\n",
    "        rocauc_list.append(rocauc)\n",
    "        f1_list.append(f1)\n",
    "        acc_list.append(acc)\n",
    "\n",
    "    return np.nan_to_num(np.nanmean(prauc_list)), np.nan_to_num(np.nanstd(prauc_list)), \\\n",
    "        np.nan_to_num(np.nanmean(rocauc_list)), np.nan_to_num(np.nanstd(rocauc_list)), \\\n",
    "        np.nan_to_num(np.nanmean(f1_list)), np.nan_to_num(np.nanstd(f1_list)), \\\n",
    "        np.nan_to_num(np.nanmean(acc_list)), np.nan_to_num(np.nanstd(acc_list))\n",
    "\n",
    "def run_baselines(train_x, train_y, test_x, test_y, random_state=1, prepend=''):\n",
    "    # logistic regression, svm, adaboost, xgboost, decision tree\n",
    "    # baselines_csv = ['Model, Test PR AUC, Test ROC AUC, Test F1, Test Acc.']\n",
    "    baselines_csv = []\n",
    "    model_names = ['Logistic Regression', 'Decision Tree', 'AdaBoost', 'Random Forest']\n",
    "    models = [sklearn.linear_model.LogisticRegression(random_state=random_state),\n",
    "        # sklearn.svm.SVC(random_state=random_state, kernel='linear', probability=True), \n",
    "        sklearn.tree.DecisionTreeClassifier(random_state=random_state),\n",
    "        sklearn.ensemble.AdaBoostClassifier(random_state=random_state),\n",
    "        sklearn.ensemble.RandomForestClassifier(random_state=random_state, n_estimators=10)]\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        preds = models[i].fit(train_x, train_y).predict_proba(test_x)\n",
    "        prauc, prauc_std, rocauc, rocauc_std, f1, f1_std, acc, acc_std = bootstrap_eval(labels=test_y, preds=preds)\n",
    "        baselines_csv.append(prepend+\"{}, {:.3f} $\\pm$ {:.3f}, {:.3f} $\\pm$ {:.3f}, {:.3f} $\\pm$ {:.3f}, {:.3f} $\\pm$ {:.3f}\".format(\\\n",
    "            model_names[i], prauc, prauc_std, rocauc, rocauc_std, f1, f1_std, acc, acc_std))\n",
    "\n",
    "    return baselines_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "train_x = list(d[d['split'].isin(['train', 'valid'])]['sentences'])\n",
    "test_x = list(d[d['split'].isin(['test'])]['sentences'])\n",
    "train_y = d[d['split'].isin(['train', 'valid'])]['label'].values\n",
    "test_y = d[d['split'].isin(['test'])]['label'].values\n",
    "\n",
    "len_train = len(train_x)\n",
    "countv = CountVectorizer()\n",
    "counts = countv.fit_transform(train_x+test_x)\n",
    "x = TfidfTransformer(use_idf=True).fit_transform(counts)\n",
    "train_x, test_x = x[:len_train], x[len_train:]\n",
    "\n",
    "ind_to_word = {v:k for k,v in countv.vocabulary_.items()}\n",
    "\n",
    "\n",
    "print(train_x.shape, test_x.shape)\n",
    "results = run_baselines(train_x, np.array(train_y), test_x, np.array(test_y), random_state=3)\n",
    "print('Model, Test PR AUC, Test ROC AUC, Test F1, Test Acc.')\n",
    "print('\\n'.join(results))\n",
    "\n",
    "# output\n",
    "\"\"\"\n",
    "Model, Test PR AUC, Test ROC AUC, Test F1, Test Acc.\n",
    "Logistic Regression, 0.876 $\\pm$ 0.009, 0.721 $\\pm$ 0.018, 0.844 $\\pm$ 0.007, 0.744 $\\pm$ 0.011\n",
    "Decision Tree, 0.781 $\\pm$ 0.013, 0.579 $\\pm$ 0.019, 0.753 $\\pm$ 0.013, 0.647 $\\pm$ 0.015\n",
    "AdaBoost, 0.823 $\\pm$ 0.010, 0.626 $\\pm$ 0.012, 0.796 $\\pm$ 0.010, 0.690 $\\pm$ 0.013\n",
    "Random Forest, 0.815 $\\pm$ 0.013, 0.631 $\\pm$ 0.022, 0.811 $\\pm$ 0.012, 0.709 $\\pm$ 0.016\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distilltab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
