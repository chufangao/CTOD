{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chufangao/CTOD/blob/main/tutorials/getting_started_cto_vs_top.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This is an entirely self-contained notebook comparing training data from our [CTO](https://chufangao.github.io/CTOD/) label predictions against [TOP] [1] (https://github.com/futianfan/clinical-trial-outcome-prediction) [2] training labels, tested on the TOP test split.\n",
        "\n",
        "[1] Gao, C., Pradeepkumar, J., Das, T., Thati, S., & Sun, J. (2024). Automatically Labeling Clinical Trial Outcomes: A Large-Scale Benchmark for Drug Development. arXiv preprint arXiv:2406.10292.\n",
        "\n",
        "[2] Fu, T., Huang, K., Xiao, C., Glass, L. M., & Sun, J. (2022). Hint: Hierarchical interaction network for clinical-trial-outcome predictions. Patterns, 3(4)."
      ],
      "metadata": {
        "id": "-jRQSeaXWFfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading in the datasets"
      ],
      "metadata": {
        "id": "JGS3s39IXFUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let us get started\n",
        "!git clone https://github.com/chufangao/CTOD.git\n",
        "!git clone https://github.com/futianfan/clinical-trial-outcome-prediction.git\n",
        "!wget https://huggingface.co/datasets/chufangao/CTO/resolve/main/CTTI.zip\n",
        "CTTI_PATH = './CTTI.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E7kQDP22wil",
        "outputId": "b4808d0e-81ab-4b43-ff6d-139ddc532fdd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CTOD'...\n",
            "remote: Enumerating objects: 487, done.\u001b[K\n",
            "remote: Counting objects: 100% (256/256), done.\u001b[K\n",
            "remote: Compressing objects: 100% (179/179), done.\u001b[K\n",
            "remote: Total 487 (delta 162), reused 142 (delta 74), pack-reused 231 (from 1)\u001b[K\n",
            "Receiving objects: 100% (487/487), 34.10 MiB | 9.20 MiB/s, done.\n",
            "Resolving deltas: 100% (262/262), done.\n",
            "Cloning into 'clinical-trial-outcome-prediction'...\n",
            "remote: Enumerating objects: 932, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 932 (delta 19), reused 40 (delta 5), pack-reused 863 (from 1)\u001b[K\n",
            "Receiving objects: 100% (932/932), 104.38 MiB | 8.07 MiB/s, done.\n",
            "Resolving deltas: 100% (534/534), done.\n",
            "Updating files: 100% (119/119), done.\n",
            "--2025-02-22 08:51:28--  https://huggingface.co/datasets/chufangao/CTO/resolve/main/CTTI.zip\n",
            "Resolving huggingface.co (huggingface.co)... 18.238.49.112, 18.238.49.10, 18.238.49.70, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.238.49.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/da/7f/da7f4412b646e319927d3efe09843fa4011826528566ace91f650c2b87e52687/fae177751917082e5d439755a26093d56fbd4002c1e89562ee7728ff80f6d06c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27CTTI.zip%3B+filename%3D%22CTTI.zip%22%3B&response-content-type=application%2Fzip&Expires=1740217888&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDIxNzg4OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2RhLzdmL2RhN2Y0NDEyYjY0NmUzMTk5MjdkM2VmZTA5ODQzZmE0MDExODI2NTI4NTY2YWNlOTFmNjUwYzJiODdlNTI2ODcvZmFlMTc3NzUxOTE3MDgyZTVkNDM5NzU1YTI2MDkzZDU2ZmJkNDAwMmMxZTg5NTYyZWU3NzI4ZmY4MGY2ZDA2Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=QERrmFfFYi5vUMY1tTiRB9u5uAqCfwNZ7jD%7ER1j5%7EJARAqNUHAgpW1WNZRJDk8A2lcjRfRLFvzACjD9ruaOUSILBBlciV-oUY-EnUWKiP15gdYdzrh3ZifpQ7sp7W9XQjhU4HuFQ8JtjdXkdlobYTiSI0APZEjYY6NmZUlw99ibHvZpKADUUFXGWQLgoo1koTOrQrj0fQUVkgF7p1effumgBA9kMzdiwAfmsEF76ks-hqt9-fONBNWI0rBSQBU6LOFlCM6vXdSvYn5VoGBkLEgkBrKngYKFgDHznNYel0-hJOvIyZfjiFWgJmGOgapHhdEgN3VZzs4s3nJzfZb4Ftg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-02-22 08:51:28--  https://cdn-lfs-us-1.hf.co/repos/da/7f/da7f4412b646e319927d3efe09843fa4011826528566ace91f650c2b87e52687/fae177751917082e5d439755a26093d56fbd4002c1e89562ee7728ff80f6d06c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27CTTI.zip%3B+filename%3D%22CTTI.zip%22%3B&response-content-type=application%2Fzip&Expires=1740217888&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDIxNzg4OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2RhLzdmL2RhN2Y0NDEyYjY0NmUzMTk5MjdkM2VmZTA5ODQzZmE0MDExODI2NTI4NTY2YWNlOTFmNjUwYzJiODdlNTI2ODcvZmFlMTc3NzUxOTE3MDgyZTVkNDM5NzU1YTI2MDkzZDU2ZmJkNDAwMmMxZTg5NTYyZWU3NzI4ZmY4MGY2ZDA2Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=QERrmFfFYi5vUMY1tTiRB9u5uAqCfwNZ7jD%7ER1j5%7EJARAqNUHAgpW1WNZRJDk8A2lcjRfRLFvzACjD9ruaOUSILBBlciV-oUY-EnUWKiP15gdYdzrh3ZifpQ7sp7W9XQjhU4HuFQ8JtjdXkdlobYTiSI0APZEjYY6NmZUlw99ibHvZpKADUUFXGWQLgoo1koTOrQrj0fQUVkgF7p1effumgBA9kMzdiwAfmsEF76ks-hqt9-fONBNWI0rBSQBU6LOFlCM6vXdSvYn5VoGBkLEgkBrKngYKFgDHznNYel0-hJOvIyZfjiFWgJmGOgapHhdEgN3VZzs4s3nJzfZb4Ftg__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.154.101.3, 18.154.101.84, 18.154.101.91, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.154.101.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2048337437 (1.9G) [application/zip]\n",
            "Saving to: ‘CTTI.zip’\n",
            "\n",
            "CTTI.zip            100%[===================>]   1.91G  40.5MB/s    in 49s     \n",
            "\n",
            "2025-02-22 08:52:18 (39.9 MB/s) - ‘CTTI.zip’ saved [2048337437/2048337437]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # if you want to use the latest version of clinical trials instead, uncomment and run this cell\n",
        "# !pip install selenium\n",
        "# !python ./CTOD/download_ctti.py\n",
        "# CTTI_PATH = './downloads/CTTI_new.zip'"
      ],
      "metadata": {
        "id": "QHFcULmA1TYH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "CTO_phase1_preds = pd.read_csv(\"https://huggingface.co/datasets/chufangao/CTO/raw/main/phase1_CTO_rf.csv\")\n",
        "CTO_phase2_preds = pd.read_csv(\"https://huggingface.co/datasets/chufangao/CTO/raw/main/phase2_CTO_rf.csv\")\n",
        "CTO_phase3_preds = pd.read_csv(\"https://huggingface.co/datasets/chufangao/CTO/raw/main/phase3_CTO_rf.csv\")"
      ],
      "metadata": {
        "id": "aJaa_TBj4eTy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_all_studies_with_features(CTTI_PATH = './CTTI.zip'):\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(CTTI_PATH, 'r') as zip_ref:\n",
        "        names = zip_ref.namelist()\n",
        "        studies = pd.read_csv(zip_ref.open([name for name in names if name.split(\"/\")[-1]=='studies.txt'][0]), sep='|')\n",
        "        diseases = pd.read_csv(zip_ref.open([name for name in names if name.split(\"/\")[-1]=='browse_conditions.txt'][0]), sep='|')\n",
        "        interventions = pd.read_csv(zip_ref.open([name for name in names if name.split(\"/\")[-1]=='interventions.txt'][0]), sep='|')\n",
        "        criteria = pd.read_csv(zip_ref.open([name for name in names if name.split(\"/\")[-1]=='eligibilities.txt'][0]), sep='|')\n",
        "        designs = pd.read_csv(zip_ref.open([name for name in names if name.split(\"/\")[-1]=='designs.txt'][0]), sep='|')\n",
        "\n",
        "        # diseases = pd.read_csv(zip_ref.open('CTTI/browse_conditions.txt'), sep='|')\n",
        "        # interventions = pd.read_csv(zip_ref.open('CTTI/interventions.txt'), sep='|')\n",
        "        # criteria = pd.read_csv(zip_ref.open('CTTI/eligibilities.txt'), sep='|')\n",
        "        # designs = pd.read_csv(zip_ref.open('CTTI/designs.txt'), sep='|')\n",
        "\n",
        "    # diseases = pd.read_csv(os.path.join(CTTI_PATH, 'browse_conditions.txt'), sep='|')\n",
        "    diseases = diseases.groupby('nct_id')['downcase_mesh_term'].apply(lambda x: ' '.join(list(x))).reset_index().rename(columns={'downcase_mesh_term': 'diseases'})\n",
        "    diseases.fillna('', inplace=True)\n",
        "\n",
        "    # interventions = pd.read_csv(os.path.join(CTTI_PATH, 'interventions.txt'), sep='|')\n",
        "    interventions = interventions.dropna(subset=['name'])\n",
        "    interventions['name'] = interventions['name'].str.lower()\n",
        "    interventions = interventions.groupby('nct_id')['name'].apply(lambda x: ' '.join(list(x))).reset_index().rename(columns={'name': 'interventions'})\n",
        "    interventions.fillna('', inplace=True)\n",
        "\n",
        "    # criteria = pd.read_csv(os.path.join(CTTI_PATH, 'eligibilities.txt'), sep='|')[['nct_id', 'criteria']]\n",
        "    criteria = criteria.dropna(subset=['criteria'])\n",
        "    criteria.drop_duplicates(subset=['nct_id'], inplace=True)\n",
        "    criteria['criteria'] = criteria['criteria'].str.lower()\n",
        "    criteria.fillna('', inplace=True)\n",
        "\n",
        "    # designs = pd.read_csv(os.path.join(CTTI_PATH, 'designs.txt'), sep='|')\n",
        "    designs = designs.fillna('')\n",
        "    designs['design'] = designs['allocation'] + ' ' + designs['intervention_model'] + ' ' + designs['observational_model'] + ' ' + designs['primary_purpose'] + ' ' + designs['time_perspective'] + ' ' + designs['masking']\n",
        "    designs['design'] = designs['design'].str.lower()\n",
        "    designs = designs[['nct_id', 'design']]\n",
        "    designs.drop_duplicates(subset=['nct_id'], inplace=True)\n",
        "    designs.fillna('', inplace=True)\n",
        "\n",
        "    # studies = pd.read_csv(os.path.join(CTTI_PATH, 'studies.txt'), sep='|')\n",
        "    studies.dropna(subset=['completion_date'], inplace=True)\n",
        "    studies['year'] = studies['completion_date'].apply(lambda x: int(x.split('-')[0]))\n",
        "\n",
        "    studies = studies.merge(diseases, on='nct_id', how='left')\n",
        "    studies = studies.merge(interventions, on='nct_id', how='left')\n",
        "    studies = studies.merge(criteria, on='nct_id', how='left')\n",
        "    studies = studies.merge(designs, on='nct_id', how='left')\n",
        "    studies['features'] = studies['phase'] + ' '  + studies['diseases'] + ' '  + studies['interventions'] + ' ' + studies['design'] + ' ' + studies['criteria']\n",
        "    studies = studies[studies['features'].str.len() > 0]\n",
        "    del diseases, interventions, criteria, designs\n",
        "    return studies\n",
        "\n",
        "studies_with_features = load_all_studies_with_features(CTTI_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RktJ8IcSQmFE",
        "outputId": "85118500-08e4-46b9-9c36-6ba1b8b2be92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ebe315baa77f>:5: DtypeWarning: Columns (46,47,48,53,68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  studies = pd.read_csv(zip_ref.open([name for name in names if name.split(\"/\")[-1]=='studies.txt'][0]), sep='|')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "studies_with_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3s8uDu9ScQB",
        "outputId": "647c726f-a3e8-48c2-c383-0eb0ad79abcc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(167012, 89)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "\n",
        "train_data_mode = 'CTO' # in ['CTO', 'TOP']\n",
        "\n",
        "# test on supervised TOP labels\n",
        "test_df = pd.concat((pd.read_csv(f) for f in glob.glob(\"./clinical-trial-outcome-prediction/data/phase*test.csv\")))\n",
        "test_df = test_df.rename(columns={'nctid': 'nct_id'})\n",
        "\n",
        "if train_data_mode == 'TOP':\n",
        "    train_df = pd.concat([pd.read_csv(f) for f in glob.glob(\"./clinical-trial-outcome-prediction/data/phase*train.csv\") + glob.glob(\"./clinical-trial-outcome-prediction/data/phase*valid.csv\")])\n",
        "    train_df = train_df.rename(columns={'nctid': 'nct_id'})\n",
        "elif train_data_mode == 'CTO':\n",
        "    # concatenate\n",
        "    studies_with_features['completion_date'] = pd.to_datetime(studies_with_features['completion_date'])\n",
        "\n",
        "    CTO_preds = pd.concat([CTO_phase1_preds[['nct_id', 'pred']], CTO_phase2_preds[['nct_id', 'pred']], CTO_phase3_preds[['nct_id', 'pred']]])\n",
        "    CTO_preds = CTO_preds.rename(columns={'pred': 'label'})\n",
        "    CTO_preds = pd.merge(CTO_preds, studies_with_features[['nct_id', 'completion_date']], on='nct_id', how='left')\n",
        "    CTO_preds.dropna(inplace=True)\n",
        "    train_df = CTO_preds[CTO_preds['completion_date'] < '2015-01-01']\n",
        "\n",
        "train_features = train_df.merge(studies_with_features[['nct_id', 'features']], on='nct_id', how='left')\n",
        "train_features.dropna(subset='features', inplace=True)\n",
        "\n",
        "test_features = test_df.merge(studies_with_features[['nct_id', 'features']], on='nct_id', how='left')\n",
        "test_features.dropna(subset='features', inplace=True)\n",
        "\n",
        "# ============ preprocess by filling NAs and dropping duplocates ============\n",
        "tfidf = TfidfVectorizer(max_features=2048, stop_words='english')\n",
        "X_train = tfidf.fit_transform(train_features['features'])\n",
        "X_test = tfidf.transform(test_features['features'])"
      ],
      "metadata": {
        "id": "d3kT_nVM6QX7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_features['features'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJPPBKGFUiXx",
        "outputId": "27fa39b3-9c62-462b-9018-3c31ec27f427"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       PHASE1/PHASE2 neoplasms, connective and soft t...\n",
            "1       PHASE1 heart diseases cardiovascular diseases ...\n",
            "2       PHASE1 respiratory tract neoplasms thoracic ne...\n",
            "3       PHASE1 neoplasms by histologic type neoplasms ...\n",
            "4       PHASE1 alcohol-related disorders substance-rel...\n",
            "                              ...                        \n",
            "3421    PHASE2 pathologic processes liver diseases dig...\n",
            "3422    PHASE2 respiratory tract neoplasms thoracic ne...\n",
            "3423    PHASE2 pneumonia, viral pneumonia respiratory ...\n",
            "3424    PHASE2 pneumonia, viral pneumonia respiratory ...\n",
            "3425    PHASE2 digestive system diseases blood platele...\n",
            "Name: features, Length: 3250, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running evaluation of machine learning baselines"
      ],
      "metadata": {
        "id": "6H_HU8N12Mec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "# from xgboost import XGBClassifier # pip install xgboost\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, average_precision_score, roc_auc_score\n",
        "\n",
        "def bootstrap_eval(y_true, y_pred, y_prob, num_samples=100):\n",
        "    f1s = []\n",
        "    aps = []\n",
        "    rocs = []\n",
        "    for _ in range(num_samples):\n",
        "        indices = np.random.choice(len(y_true), len(y_true), replace=True)\n",
        "        f1s.append(f1_score(y_true[indices], y_pred[indices]))\n",
        "        aps.append(average_precision_score(y_true[indices], y_prob[indices]))\n",
        "        rocs.append(roc_auc_score(y_true[indices], y_prob[indices]))\n",
        "    return np.mean(f1s), np.std(f1s), np.mean(aps), np.std(aps), np.mean(rocs), np.std(rocs)\n",
        "\n",
        "print(train_data_mode)\n",
        "print(f'Model, Phase, F1, AP, ROC')\n",
        "# for model_name in ['svm', 'xgboost', 'mlp', 'rf', 'lr', ]:\n",
        "for model_name in ['svm', 'lr']: # use fastest models for testing\n",
        "    if model_name == 'rf':\n",
        "        model = RandomForestClassifier(n_estimators=300, random_state=0, max_depth=10, n_jobs=4)\n",
        "    elif model_name == 'lr':\n",
        "        model = LogisticRegression(max_iter=1000, random_state=0)\n",
        "    elif model_name == 'svm':\n",
        "        model = LinearSVC(dual=\"auto\", max_iter=10000, random_state=0)\n",
        "        model = CalibratedClassifierCV(model)\n",
        "        # model = SVC(kernel='linear', probability=True, random_state=0) # performs worse than the above\n",
        "    # elif model_name == 'xgboost':\n",
        "    #     model = XGBClassifier(n_estimators=300, random_state=0, max_depth=10, n_jobs=4)\n",
        "    elif model_name == 'mlp':\n",
        "        model = MLPClassifier(hidden_layer_sizes=(64, 64), max_iter=2000, random_state=0)\n",
        "    else:\n",
        "        raise ValueError('Unknown model name')\n",
        "\n",
        "    model.fit(X_train, train_features['label'])\n",
        "    test_features['pred'] = model.predict(X_test)\n",
        "    test_features['prob'] = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    for phase in ['1', '2', '3']:\n",
        "        test_df_subset = test_features[test_features['phase'].str.lower().str.contains(phase)]\n",
        "        f1_mean, f1_std, ap_mean, ap_std, roc_mean, roc_std = bootstrap_eval(test_df_subset['label'].values, test_df_subset['pred'].values, test_df_subset['prob'].values)\n",
        "        print(f\"{phase}, {model_name}, {f1_mean:.3f}, {f1_std:.3f}, {ap_mean:.3f}, {ap_std:.3f}, {roc_mean:.3f}, {roc_std:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUIbrntcUdyV",
        "outputId": "d6ecceb5-165a-4297-c741-f79f53b37f78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTO\n",
            "Model, Phase, F1, AP, ROC\n",
            "1, svm, 0.732, 0.016, 0.680, 0.024, 0.630, 0.020\n",
            "2, svm, 0.725, 0.010, 0.651, 0.015, 0.616, 0.013\n",
            "3, svm, 0.849, 0.008, 0.807, 0.015, 0.626, 0.016\n",
            "1, lr, 0.730, 0.015, 0.694, 0.025, 0.652, 0.017\n",
            "2, lr, 0.728, 0.009, 0.668, 0.019, 0.630, 0.015\n",
            "3, lr, 0.851, 0.008, 0.814, 0.015, 0.636, 0.017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "CTO\n",
        "Model, Phase, F1, AP, ROC\n",
        "1, svm, 0.731, 0.017, 0.685, 0.025, 0.634, 0.020\n",
        "2, svm, 0.724, 0.010, 0.652, 0.016, 0.619, 0.012\n",
        "3, svm, 0.849, 0.009, 0.808, 0.015, 0.628, 0.017\n",
        "1, lr, 0.733, 0.014, 0.695, 0.023, 0.651, 0.020\n",
        "2, lr, 0.727, 0.010, 0.669, 0.016, 0.631, 0.012\n",
        "3, lr, 0.849, 0.009, 0.813, 0.017, 0.638, 0.018\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "VNNHFg1CWg45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "TOP\n",
        "Model, Phase, F1, AP, ROC\n",
        "1, svm, 0.617, 0.018, 0.638, 0.025, 0.559, 0.019\n",
        "2, svm, 0.660, 0.013, 0.656, 0.016, 0.614, 0.013\n",
        "3, svm, 0.810, 0.009, 0.865, 0.011, 0.697, 0.015\n",
        "1, lr, 0.642, 0.022, 0.682, 0.028, 0.613, 0.022\n",
        "2, lr, 0.676, 0.011, 0.693, 0.015, 0.645, 0.012\n",
        "3, lr, 0.832, 0.010, 0.882, 0.012, 0.728, 0.016\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dywuNAJOWY9n"
      }
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}