{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/chufangao/CTOD.git\n",
        "!git clone https://github.com/futianfan/clinical-trial-outcome-prediction.git\n",
        "!wget https://huggingface.co/datasets/chufangao/CTO/resolve/main/CTTI.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E7kQDP22wil",
        "outputId": "b161654e-976f-405f-c354-443394e68673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CTOD' already exists and is not an empty directory.\n",
            "fatal: destination path 'clinical-trial-outcome-prediction' already exists and is not an empty directory.\n",
            "--2025-02-21 11:29:41--  https://huggingface.co/datasets/chufangao/CTO/resolve/main/CTTI.zip\n",
            "Resolving huggingface.co (huggingface.co)... 18.238.136.32, 18.238.136.129, 18.238.136.112, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.238.136.32|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/da/7f/da7f4412b646e319927d3efe09843fa4011826528566ace91f650c2b87e52687/fae177751917082e5d439755a26093d56fbd4002c1e89562ee7728ff80f6d06c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27CTTI.zip%3B+filename%3D%22CTTI.zip%22%3B&response-content-type=application%2Fzip&Expires=1740140981&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDE0MDk4MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2RhLzdmL2RhN2Y0NDEyYjY0NmUzMTk5MjdkM2VmZTA5ODQzZmE0MDExODI2NTI4NTY2YWNlOTFmNjUwYzJiODdlNTI2ODcvZmFlMTc3NzUxOTE3MDgyZTVkNDM5NzU1YTI2MDkzZDU2ZmJkNDAwMmMxZTg5NTYyZWU3NzI4ZmY4MGY2ZDA2Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=ehRac%7ESUh679hlVXGiUmm9KNo9OVpdQfX3-GLgRrhJUuGgTxw4TS3Iwi-huSzDS-opOdC36q9LYOrJUT0J-Pfd2J4m9zguiuEDdss%7EVxH0M9oDrWSiKpbapNpBqhBtexxMiBBExgUdIrMLrLvvBPekMzh64QUYTen9WEyGB54zSF7Fob1SyFk-fMBafY3-Dp50inBatS417DtvAxwqGKu5emSR6aJ-Gn4RapxA9A7LNg%7EcD1-qXGiKEqoT9s43CgWFEzm%7Efk5yQHQyxAFbOLCKrlgr2hrgDbFqUvc%7EFJLyS8AdTCXKzi%7E3KmdF2LLXCqg4eaaVYSIyezZg3o7KstpQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-02-21 11:29:41--  https://cdn-lfs-us-1.hf.co/repos/da/7f/da7f4412b646e319927d3efe09843fa4011826528566ace91f650c2b87e52687/fae177751917082e5d439755a26093d56fbd4002c1e89562ee7728ff80f6d06c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27CTTI.zip%3B+filename%3D%22CTTI.zip%22%3B&response-content-type=application%2Fzip&Expires=1740140981&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDE0MDk4MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2RhLzdmL2RhN2Y0NDEyYjY0NmUzMTk5MjdkM2VmZTA5ODQzZmE0MDExODI2NTI4NTY2YWNlOTFmNjUwYzJiODdlNTI2ODcvZmFlMTc3NzUxOTE3MDgyZTVkNDM5NzU1YTI2MDkzZDU2ZmJkNDAwMmMxZTg5NTYyZWU3NzI4ZmY4MGY2ZDA2Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=ehRac%7ESUh679hlVXGiUmm9KNo9OVpdQfX3-GLgRrhJUuGgTxw4TS3Iwi-huSzDS-opOdC36q9LYOrJUT0J-Pfd2J4m9zguiuEDdss%7EVxH0M9oDrWSiKpbapNpBqhBtexxMiBBExgUdIrMLrLvvBPekMzh64QUYTen9WEyGB54zSF7Fob1SyFk-fMBafY3-Dp50inBatS417DtvAxwqGKu5emSR6aJ-Gn4RapxA9A7LNg%7EcD1-qXGiKEqoT9s43CgWFEzm%7Efk5yQHQyxAFbOLCKrlgr2hrgDbFqUvc%7EFJLyS8AdTCXKzi%7E3KmdF2LLXCqg4eaaVYSIyezZg3o7KstpQ__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.160.225.98, 18.160.225.13, 18.160.225.120, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.160.225.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2048337437 (1.9G) [application/zip]\n",
            "Saving to: ‘CTTI.zip.1’\n",
            "\n",
            "CTTI.zip.1          100%[===================>]   1.91G  40.0MB/s    in 48s     \n",
            "\n",
            "2025-02-21 11:30:29 (40.3 MB/s) - ‘CTTI.zip.1’ saved [2048337437/2048337437]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "CTO_phase1_preds = pd.read_csv(\"https://huggingface.co/datasets/chufangao/CTO/raw/main/phase1_CTO_rf.csv\")\n",
        "CTO_phase2_preds = pd.read_csv(\"https://huggingface.co/datasets/chufangao/CTO/raw/main/phase2_CTO_rf.csv\")\n",
        "CTO_phase3_preds = pd.read_csv(\"https://huggingface.co/datasets/chufangao/CTO/raw/main/phase3_CTO_rf.csv\")"
      ],
      "metadata": {
        "id": "aJaa_TBj4eTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_all_studies_with_features():\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(\"./CTTI.zip\", 'r') as zip_ref:\n",
        "        studies = pd.read_csv(zip_ref.open('CTTI/studies.txt'), sep='|')\n",
        "        diseases = pd.read_csv(zip_ref.open('CTTI/browse_conditions.txt'), sep='|')\n",
        "        interventions = pd.read_csv(zip_ref.open('CTTI/interventions.txt'), sep='|')\n",
        "        criteria = pd.read_csv(zip_ref.open('CTTI/eligibilities.txt'), sep='|')\n",
        "        designs = pd.read_csv(zip_ref.open('CTTI/designs.txt'), sep='|')\n",
        "\n",
        "    # diseases = pd.read_csv(os.path.join(CTTI_PATH, 'browse_conditions.txt'), sep='|')\n",
        "    diseases = diseases.groupby('nct_id')['downcase_mesh_term'].apply(lambda x: ' '.join(list(x))).reset_index().rename(columns={'downcase_mesh_term': 'diseases'})\n",
        "    diseases.fillna('', inplace=True)\n",
        "\n",
        "    # interventions = pd.read_csv(os.path.join(CTTI_PATH, 'interventions.txt'), sep='|')\n",
        "    interventions = interventions.dropna(subset=['name'])\n",
        "    interventions['name'] = interventions['name'].str.lower()\n",
        "    interventions = interventions.groupby('nct_id')['name'].apply(lambda x: ' '.join(list(x))).reset_index().rename(columns={'name': 'interventions'})\n",
        "    interventions.fillna('', inplace=True)\n",
        "\n",
        "    # criteria = pd.read_csv(os.path.join(CTTI_PATH, 'eligibilities.txt'), sep='|')[['nct_id', 'criteria']]\n",
        "    criteria = criteria.dropna(subset=['criteria'])\n",
        "    criteria.drop_duplicates(subset=['nct_id'], inplace=True)\n",
        "    criteria['criteria'] = criteria['criteria'].str.lower()\n",
        "    criteria.fillna('', inplace=True)\n",
        "\n",
        "    # designs = pd.read_csv(os.path.join(CTTI_PATH, 'designs.txt'), sep='|')\n",
        "    designs = designs.fillna('')\n",
        "    designs['design'] = designs['allocation'] + ' ' + designs['intervention_model'] + ' ' + designs['observational_model'] + ' ' + designs['primary_purpose'] + ' ' + designs['time_perspective'] + ' ' + designs['masking']\n",
        "    designs['design'] = designs['design'].str.lower()\n",
        "    designs = designs[['nct_id', 'design']]\n",
        "    designs.drop_duplicates(subset=['nct_id'], inplace=True)\n",
        "    designs.fillna('', inplace=True)\n",
        "\n",
        "    # studies = pd.read_csv(os.path.join(CTTI_PATH, 'studies.txt'), sep='|')\n",
        "    studies.dropna(subset=['completion_date'], inplace=True)\n",
        "    studies['year'] = studies['completion_date'].apply(lambda x: int(x.split('-')[0]))\n",
        "\n",
        "    studies = studies.merge(diseases, on='nct_id', how='left')\n",
        "    studies = studies.merge(interventions, on='nct_id', how='left')\n",
        "    studies = studies.merge(criteria, on='nct_id', how='left')\n",
        "    studies = studies.merge(designs, on='nct_id', how='left')\n",
        "    studies['features'] = studies['phase'] + ' '  + studies['diseases'] + ' '  + studies['interventions'] + ' ' + studies['design'] + ' ' + studies['criteria']\n",
        "    studies = studies[studies['features'].str.len() > 0]\n",
        "    del diseases, interventions, criteria, designs\n",
        "    return studies\n",
        "\n",
        "# ============ define evalution ============\n",
        "from sklearn.metrics import classification_report, f1_score, average_precision_score, roc_auc_score\n",
        "\n",
        "def bootstrap_eval(y_true, y_pred, y_prob, num_samples=100):\n",
        "    f1s = []\n",
        "    aps = []\n",
        "    rocs = []\n",
        "    for _ in range(num_samples):\n",
        "        indices = np.random.choice(len(y_true), len(y_true), replace=True)\n",
        "        f1s.append(f1_score(y_true[indices], y_pred[indices]))\n",
        "        aps.append(average_precision_score(y_true[indices], y_prob[indices]))\n",
        "        rocs.append(roc_auc_score(y_true[indices], y_prob[indices]))\n",
        "    return np.mean(f1s), np.std(f1s), np.mean(aps), np.std(aps), np.mean(rocs), np.std(rocs)\n",
        "studies_with_features = load_all_studies_with_features()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RktJ8IcSQmFE",
        "outputId": "a44cac6a-4b44-47cd-b4ad-f3cab8a7d64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-a520480b9139>:4: DtypeWarning: Columns (46,47,48,53,68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  studies = pd.read_csv(zip_ref.open('CTTI/studies.txt'), sep='|')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "studies_with_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3s8uDu9ScQB",
        "outputId": "fe8918c3-b9c7-4113-d623-2ccd3d2e77a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(167012, 89)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "\n",
        "train_data_mode = 'CTO' # in ['CTO', 'TOP']\n",
        "\n",
        "# test on supervised TOP labels\n",
        "test_df = pd.concat((pd.read_csv(f) for f in glob.glob(\"./clinical-trial-outcome-prediction/data/phase*test.csv\")))\n",
        "test_df = test_df.rename(columns={'nctid': 'nct_id'})\n",
        "\n",
        "if train_data_mode == 'TOP':\n",
        "    train_df = pd.concat([pd.read_csv(f) for f in glob.glob(\"./clinical-trial-outcome-prediction/data/phase*train.csv\") + glob.glob(\"./clinical-trial-outcome-prediction/data/phase*valid.csv\")])\n",
        "    train_df = train_df.rename(columns={'nctid': 'nct_id'})\n",
        "elif train_data_mode == 'CTO':\n",
        "    # concatenate\n",
        "    studies_with_features['completion_date'] = pd.to_datetime(studies_with_features['completion_date'])\n",
        "\n",
        "    CTO_preds = pd.concat([CTO_phase1_preds[['nct_id', 'pred']], CTO_phase2_preds[['nct_id', 'pred']], CTO_phase3_preds[['nct_id', 'pred']]])\n",
        "    CTO_preds = CTO_preds.rename(columns={'pred': 'label'})\n",
        "    CTO_preds = pd.merge(CTO_preds, studies_with_features[['nct_id', 'completion_date']], on='nct_id', how='left')\n",
        "    CTO_preds.dropna(inplace=True)\n",
        "    train_df = CTO_preds[CTO_preds['completion_date'] < '2015-01-01']\n",
        "\n",
        "train_features = train_df.merge(studies_with_features[['nct_id', 'features']], on='nct_id', how='left')\n",
        "train_features.dropna(subset='features', inplace=True)\n",
        "\n",
        "test_features = test_df.merge(studies_with_features[['nct_id', 'features']], on='nct_id', how='left')\n",
        "test_features.dropna(subset='features', inplace=True)\n",
        "\n",
        "# ============ preprocess by filling NAs and dropping duplocates ============\n",
        "tfidf = TfidfVectorizer(max_features=2048, stop_words='english')\n",
        "X_train = tfidf.fit_transform(train_features['features'])\n",
        "X_test = tfidf.transform(test_features['features'])"
      ],
      "metadata": {
        "id": "d3kT_nVM6QX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_features['features'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJPPBKGFUiXx",
        "outputId": "bbe6a747-c2d0-4929-cf91-c1099911437b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       PHASE1/PHASE2 neoplasms, connective and soft t...\n",
            "1       PHASE1 heart diseases cardiovascular diseases ...\n",
            "2       PHASE1 respiratory tract neoplasms thoracic ne...\n",
            "3       PHASE1 neoplasms by histologic type neoplasms ...\n",
            "4       PHASE1 alcohol-related disorders substance-rel...\n",
            "                              ...                        \n",
            "3421    PHASE3 pain neurologic manifestations acute pa...\n",
            "3423    PHASE3 skin diseases skin diseases, genetic ge...\n",
            "3424    PHASE2/PHASE3 muscular disorders, atrophic mus...\n",
            "3425    PHASE3 connective tissue diseases autoimmune d...\n",
            "3426    PHASE3 disease attributes pathologic processes...\n",
            "Name: features, Length: 3250, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "# from xgboost import XGBClassifier # pip install xgboost\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "print(train_data_mode)\n",
        "print(f'Model, Phase, F1, AP, ROC')\n",
        "# for model_name in ['svm', 'xgboost', 'mlp', 'rf', 'lr', ]:\n",
        "for model_name in ['svm', 'lr']: # use fastest models for testing\n",
        "    if model_name == 'rf':\n",
        "        model = RandomForestClassifier(n_estimators=300, random_state=0, max_depth=10, n_jobs=4)\n",
        "    elif model_name == 'lr':\n",
        "        model = LogisticRegression(max_iter=1000, random_state=0)\n",
        "    elif model_name == 'svm':\n",
        "        model = LinearSVC(dual=\"auto\", max_iter=10000, random_state=0)\n",
        "        model = CalibratedClassifierCV(model)\n",
        "        # model = SVC(kernel='linear', probability=True, random_state=0) # performs worse than the above\n",
        "    elif model_name == 'xgboost':\n",
        "        model = XGBClassifier(n_estimators=300, random_state=0, max_depth=10, n_jobs=4)\n",
        "    elif model_name == 'mlp':\n",
        "        model = MLPClassifier(hidden_layer_sizes=(64, 64), max_iter=2000, random_state=0)\n",
        "    else:\n",
        "        raise ValueError('Unknown model name')\n",
        "\n",
        "    model.fit(X_train, train_features['label'])\n",
        "    test_features['pred'] = model.predict(X_test)\n",
        "    test_features['prob'] = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    for phase in ['1', '2', '3']:\n",
        "        test_df_subset = test_features[test_features['phase'].str.lower().str.contains(phase)]\n",
        "        f1_mean, f1_std, ap_mean, ap_std, roc_mean, roc_std = bootstrap_eval(test_df_subset['label'].values, test_df_subset['pred'].values, test_df_subset['prob'].values)\n",
        "        print(f\"{phase}, {model_name}, {f1_mean:.3f}, {f1_std:.3f}, {ap_mean:.3f}, {ap_std:.3f}, {roc_mean:.3f}, {roc_std:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUIbrntcUdyV",
        "outputId": "09b91fd3-631f-40ef-b61b-253a36f21b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTO\n",
            "Model, Phase, F1, AP, ROC\n",
            "1, svm, 0.731, 0.017, 0.685, 0.025, 0.634, 0.020\n",
            "2, svm, 0.724, 0.010, 0.652, 0.016, 0.619, 0.012\n",
            "3, svm, 0.849, 0.009, 0.808, 0.015, 0.628, 0.017\n",
            "1, lr, 0.733, 0.014, 0.695, 0.023, 0.651, 0.020\n",
            "2, lr, 0.727, 0.010, 0.669, 0.016, 0.631, 0.012\n",
            "3, lr, 0.849, 0.009, 0.813, 0.017, 0.638, 0.018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "CTO\n",
        "Model, Phase, F1, AP, ROC\n",
        "1, svm, 0.731, 0.017, 0.685, 0.025, 0.634, 0.020\n",
        "2, svm, 0.724, 0.010, 0.652, 0.016, 0.619, 0.012\n",
        "3, svm, 0.849, 0.009, 0.808, 0.015, 0.628, 0.017\n",
        "1, lr, 0.733, 0.014, 0.695, 0.023, 0.651, 0.020\n",
        "2, lr, 0.727, 0.010, 0.669, 0.016, 0.631, 0.012\n",
        "3, lr, 0.849, 0.009, 0.813, 0.017, 0.638, 0.018\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "VNNHFg1CWg45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "TOP\n",
        "Model, Phase, F1, AP, ROC\n",
        "1, svm, 0.617, 0.018, 0.638, 0.025, 0.559, 0.019\n",
        "2, svm, 0.660, 0.013, 0.656, 0.016, 0.614, 0.013\n",
        "3, svm, 0.810, 0.009, 0.865, 0.011, 0.697, 0.015\n",
        "1, lr, 0.642, 0.022, 0.682, 0.028, 0.613, 0.022\n",
        "2, lr, 0.676, 0.011, 0.693, 0.015, 0.645, 0.012\n",
        "3, lr, 0.832, 0.010, 0.882, 0.012, 0.728, 0.016\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dywuNAJOWY9n"
      }
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}