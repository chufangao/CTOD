{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a Tutorial Notebook to get started with CTO as soon as possible, without any frills\n",
    "- We will be attempting to reproduce baseline result:\n",
    "    - Training on CTO training labels and testing on TOP test split\n",
    "- Prequisites:\n",
    "    - pip install all requirements as in the requirements.txt\n",
    "    - Navigate to https://zenodo.org/doi/10.5281/zenodo.11535960 (this link always resolves to the latest version), and download the latest version of CTO! \n",
    "    I downloaded the v0.3 labeling.zip, and placed it in the parent directory.\n",
    "    - Also git clone TOP for comparison purposes\n",
    "        ```bash\n",
    "        wget https://zenodo.org/records/11608615/files/labeling.zip -P ../\n",
    "        git clone https://github.com/futianfan/clinical-trial-outcome-prediction ../\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the zipped data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "\n",
    "train_data_mode = 'CTO' # in ['CTO', 'TOP']\n",
    "\n",
    "# we always test on supervised TOP labels\n",
    "test_df = pd.concat((pd.read_csv(f) for f in glob.glob(\"../clinical-trial-outcome-prediction/data/phase*test.csv\")))\n",
    "\n",
    "if train_data_mode == 'TOP':\n",
    "    train_df = pd.concat((pd.read_csv(f) for f in glob.glob(\"../clinical-trial-outcome-prediction/data/phase*train.csv\")))\n",
    "    valid_df = pd.concat((pd.read_csv(f) for f in glob.glob(\"../clinical-trial-outcome-prediction/data/phase*valid.csv\")))\n",
    "\n",
    "elif train_data_mode == 'CTO':\n",
    "    with zipfile.ZipFile('../labeling.zip', 'r') as zip_ref:\n",
    "        all_names = zip_ref.namelist()\n",
    "        # print(all_names)\n",
    "        # print([_ for _ in all_names if \"vs_top\" in _])\n",
    "        train_df = pd.read_csv(zip_ref.open('labeling/vs_top/train_dp.csv'))\n",
    "        valid_df = pd.read_csv(zip_ref.open('labeling/vs_top/valid_dp.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# ============ preprocess by filling NAs and dropping duplocates ============\n",
    "train_df = pd.concat([train_df, valid_df])\n",
    "train_df.fillna('', inplace=True)\n",
    "train_df.drop_duplicates(subset=['nctid'], inplace=True)\n",
    "test_df.fillna('', inplace=True)\n",
    "test_df.drop_duplicates(subset=['nctid'], inplace=True)\n",
    "\n",
    "# ============ set features to phase + diseases + icdcodes + drugs + inclusion / exclusion criteria ============\n",
    "train_df['features'] = train_df['phase'] + ' '  + train_df['diseases'] + ' '  + train_df['icdcodes'] + ' ' + train_df['drugs'] + ' ' + train_df['criteria']\n",
    "test_df['features'] = test_df['phase'] + ' '  + test_df['diseases'] + ' '  + test_df['icdcodes'] + ' ' + test_df['drugs'] + ' ' + test_df['criteria']\n",
    "\n",
    "# featurize the data\n",
    "tfidf = TfidfVectorizer(max_features=2048, stop_words='english')\n",
    "X_train = tfidf.fit_transform(train_df['features'])\n",
    "X_test = tfidf.transform(test_df['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ define evalution ============\n",
    "from sklearn.metrics import classification_report, f1_score, average_precision_score, roc_auc_score\n",
    "\n",
    "def bootstrap_eval(y_true, y_pred, y_prob, num_samples=100):\n",
    "    f1s = []\n",
    "    aps = []\n",
    "    rocs = []\n",
    "    for _ in range(num_samples):\n",
    "        indices = np.random.choice(len(y_true), len(y_true), replace=True)\n",
    "        f1s.append(f1_score(y_true[indices], y_pred[indices]))\n",
    "        aps.append(average_precision_score(y_true[indices], y_prob[indices]))\n",
    "        rocs.append(roc_auc_score(y_true[indices], y_prob[indices]))\n",
    "    return np.mean(f1s), np.std(f1s), np.mean(aps), np.std(aps), np.mean(rocs), np.std(rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, Phase, F1, AP, ROC\n",
      "phase 1, svm, 0.711, 0.015, 0.639, 0.027, 0.618, 0.023\n",
      "phase 2, svm, 0.718, 0.009, 0.644, 0.017, 0.613, 0.015\n",
      "phase 3, svm, 0.854, 0.007, 0.839, 0.013, 0.653, 0.018\n",
      "phase 1, lr, 0.727, 0.016, 0.692, 0.025, 0.657, 0.020\n",
      "phase 2, lr, 0.718, 0.010, 0.680, 0.017, 0.639, 0.013\n",
      "phase 3, lr, 0.857, 0.008, 0.849, 0.014, 0.676, 0.018\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "# from xgboost import XGBClassifier # pip install xgboost\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "print(f'Model, Phase, F1, AP, ROC')\n",
    "# for model_name in ['svm', 'xgboost', 'mlp', 'rf', 'lr', ]:\n",
    "for model_name in ['svm', 'lr']: # use fastest models for testing\n",
    "    if model_name == 'rf':\n",
    "        model = RandomForestClassifier(n_estimators=300, random_state=0, max_depth=10, n_jobs=4)\n",
    "    elif model_name == 'lr':\n",
    "        model = LogisticRegression(max_iter=1000, random_state=0)\n",
    "    elif model_name == 'svm':\n",
    "        model = LinearSVC(dual=\"auto\", max_iter=10000, random_state=0)\n",
    "        model = CalibratedClassifierCV(model) \n",
    "        # model = SVC(kernel='linear', probability=True, random_state=0) # performs worse than the above\n",
    "    elif model_name == 'xgboost':\n",
    "        model = XGBClassifier(n_estimators=300, random_state=0, max_depth=10, n_jobs=4)\n",
    "    elif model_name == 'mlp':\n",
    "        model = MLPClassifier(hidden_layer_sizes=(64, 64), max_iter=2000, random_state=0)\n",
    "    else:\n",
    "        raise ValueError('Unknown model name')\n",
    "\n",
    "    model.fit(X_train, train_df['label'])\n",
    "    test_df['pred'] = model.predict(X_test)\n",
    "    test_df['prob'] = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    for phase in ['phase 1', 'phase 2', 'phase 3']:\n",
    "        test_df_subset = test_df[test_df['phase'].str.lower().str.contains(phase)]\n",
    "        f1_mean, f1_std, ap_mean, ap_std, roc_mean, roc_std = bootstrap_eval(test_df_subset['label'].values, test_df_subset['pred'].values, test_df_subset['prob'].values)\n",
    "        print(f\"{phase}, {model_name}, {f1_mean:.3f}, {f1_std:.3f}, {ap_mean:.3f}, {ap_std:.3f}, {roc_mean:.3f}, {roc_std:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Results: train on CTO, test on TOP ==================\n",
    "# Model, Phase, F1, AP, ROC\n",
    "# phase 1, svm, 0.715, 0.014, 0.648, 0.030, 0.624, 0.025\n",
    "# phase 2, svm, 0.718, 0.011, 0.645, 0.019, 0.614, 0.015\n",
    "# phase 3, svm, 0.854, 0.009, 0.841, 0.015, 0.656, 0.020\n",
    "# phase 1, lr, 0.725, 0.015, 0.691, 0.029, 0.658, 0.023\n",
    "# phase 2, lr, 0.716, 0.011, 0.679, 0.016, 0.641, 0.012\n",
    "# phase 3, lr, 0.856, 0.008, 0.845, 0.015, 0.669, 0.020\n",
    "\n",
    "# ================== Results: train on TOP, test on TOP ==================\n",
    "# Model, Phase, F1, AP, ROC\n",
    "# phase 1, svm, 0.627, 0.020, 0.642, 0.028, 0.590, 0.022\n",
    "# phase 2, svm, 0.670, 0.013, 0.662, 0.019, 0.625, 0.013\n",
    "# phase 3, svm, 0.812, 0.009, 0.873, 0.012, 0.699, 0.016\n",
    "# phase 1, lr, 0.652, 0.018, 0.664, 0.027, 0.627, 0.020\n",
    "# phase 2, lr, 0.674, 0.012, 0.697, 0.018, 0.648, 0.013\n",
    "# phase 3, lr, 0.827, 0.010, 0.885, 0.012, 0.723, 0.015"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
